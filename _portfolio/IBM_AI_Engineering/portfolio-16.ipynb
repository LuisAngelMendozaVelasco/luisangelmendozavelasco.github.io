{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LuisAngelMendozaVelasco/luisangelmendozavelasco.github.io/blob/master/_portfolio/IBM_AI_Engineering/portfolio-16.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Create a Recurrent Neural Network focused on Language Modelling and reach low levels of perplexity on the Penn Treebank dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Language Modelling](https://en.wikipedia.org/wiki/Language_model) is the task of assigning probabilities to sequences of words. This means that, given a context of one or a sequence of words in the language the model was trained on, the model should provide the next most probable words or sequence of words that follows from the given sequence of words the sentence. This kind of analysis is very important for language-related tasks such as [Speech Recognition](https://en.wikipedia.org/wiki/Speech_recognition), [Machine Translation](https://en.wikipedia.org/wiki/Machine_translation), [Image Captioning](https://en.wikipedia.org/wiki/Automatic_image_annotation), Text Correction and many other very relevant problems. Language Modelling is one of the most important tasks in [Natural Language Processing (NLP)](https://en.wikipedia.org/wiki/Natural_language_processing).\n",
    "\n",
    "For Language Modelling problems, [perplexity](https://en.wikipedia.org/wiki/Perplexity) is the way to gauge efficiency. Perplexity is simply a measure of how well a probabilistic model is able to predict its sample. A higher-level way to explain this would be saying that low perplexity means a higher degree of trust in the predictions the model makes. Therefore, the lower perplexity is, the better.\n",
    "\n",
    "A [Recurrent Neural Network (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) is a type of artificial neural network designed to handle sequential data by incorporating feedback loops. Unlike traditional feedforward neural networks, RNNs process data across multiple time steps, allowing them to maintain a form of memory that captures information from previous inputs. This feature makes RNNs particularly useful for tasks involving text, speech, and time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 01:01:07.086081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741330867.099724  383388 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741330867.103949  383388 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 01:01:07.117634: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, Input, layers, optimizers, losses\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File '/tmp/simple-examples.tgz' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget -nc --progress=bar:force:noscroll http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz -P /tmp\n",
    "tar -xf /tmp/simple-examples.tgz --skip-old-files -C /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historically, datasets big enough for Natural Language Processing are hard to come by. This is in part due to the necessity of the sentences to be broken down and tagged with a certain degree of correctness, or else the models trained on it won't be able to be correct at all. This means that we need a large amount of data, annotated by or at least corrected by humans. This is, of course, not an easy task at all.\n",
    "\n",
    "The [Penn Treebank](https://catalog.ldc.upenn.edu/docs/LDC95T7/cl93.html), or PTB for short, is a dataset maintained by the University of Pennsylvania. It is huge, there are over four million and eight hundred thousand annotated words in it, all corrected by humans. It is composed of many different sources, from abstracts of Department of Energy papers to texts from the Library of America. Since it is verifiably correct and of such a huge size, the Penn Treebank is commonly used as a benchmark dataset for Language Modelling.\n",
    "\n",
    "The dataset is divided in different kinds of annotations, such as Piece-of-Speech, Syntactic and Semantic skeletons. For this example, we will simply use a sample of clean, non-annotated words (with the exception of one tag, <unk> , which is used for rare words such as uncommon proper nouns) for our model. This means that we just want to predict what the next words would be, not what they mean in context or their classes on a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# \"\"\"Utilities for parsing PTB text files.\"\"\"\n",
    "\n",
    "def _read_words(filename):\n",
    "    with tf.io.gfile.GFile(filename, \"r\") as f:\n",
    "        return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "def _build_vocab(filename):\n",
    "    data = _read_words(filename)\n",
    "\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "    return word_to_id\n",
    "\n",
    "def _file_to_word_ids(filename, word_to_id):\n",
    "    data = _read_words(filename)\n",
    "\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "def ptb_raw_data(data_path=None):\n",
    "    \"\"\"Load PTB raw data from data directory \"data_path\".\n",
    "\n",
    "    Reads PTB text files, converts strings to integer ids,\n",
    "    and performs mini-batching of the inputs.\n",
    "\n",
    "    The PTB dataset comes from Tomas Mikolov's webpage:\n",
    "\n",
    "    http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "\n",
    "    Args:\n",
    "        data_path: string path to the directory where simple-examples.tgz has\n",
    "        been extracted.\n",
    "\n",
    "    Returns:\n",
    "        tuple (train_data, valid_data, test_data, vocabulary)\n",
    "        where each of the data objects can be passed to PTBIterator.\n",
    "    \"\"\"\n",
    "\n",
    "    train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "    test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "    word_to_id = _build_vocab(train_path)\n",
    "    train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "\n",
    "    return train_data, valid_data, test_data, vocabulary, word_to_id\n",
    "\n",
    "def ptb_iterator(raw_data, batch_size, num_steps):\n",
    "    \"\"\"Iterate on the raw PTB data.\n",
    "\n",
    "    This generates batch_size pointers into the raw PTB data, and allows\n",
    "    minibatch iteration along these pointers.\n",
    "\n",
    "    Args:\n",
    "        raw_data: one of the raw data outputs from ptb_raw_data.\n",
    "        batch_size: int, the batch size.\n",
    "        num_steps: int, the number of unrolls.\n",
    "\n",
    "    Yields:\n",
    "        Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n",
    "        The second element of the tuple is the same data time-shifted to the\n",
    "        right by one.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if batch_size or num_steps are too high.\n",
    "    \"\"\"\n",
    "\n",
    "    raw_data = np.array(raw_data, dtype=np.int32)\n",
    "\n",
    "    data_len = len(raw_data)\n",
    "    batch_len = data_len // batch_size\n",
    "    data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
    "\n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "\n",
    "    if epoch_size == 0:\n",
    "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data[:, i * num_steps + 1:(i + 1) * num_steps + 1]\n",
    "        \n",
    "        yield (x, y)\n",
    "\n",
    "def id_to_word(id_list, word_to_id):\n",
    "    line = []\n",
    "\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 929589\n",
      "Number of validation samples: 73760\n",
      "Number of test samples: 82430\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data, vocabulary, word_to_id = ptb_raw_data(\"/tmp/simple-examples/data\")\n",
    "\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(valid_data))\n",
    "print(\"Number of test samples:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a list of words represented by numbers, e.g. [0, 1, 2, 3,...]. Let's look at a sequence of words and their corresponding number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1132 -> consumers',\n",
       " '93 -> may',\n",
       " '358 -> want',\n",
       " '5 -> to',\n",
       " '329 -> move',\n",
       " '51 -> their',\n",
       " '9836 -> telephones',\n",
       " '6 -> a',\n",
       " '326 -> little',\n",
       " '2476 -> closer',\n",
       " '5 -> to',\n",
       " '0 -> the',\n",
       " '662 -> tv',\n",
       " '388 -> set',\n",
       " '2 -> <eos>',\n",
       " '1 -> <unk>',\n",
       " '1 -> <unk>',\n",
       " '2974 -> watching',\n",
       " '2158 -> abc',\n",
       " \"9 -> 's\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(number) + \" -> \" + word for number, word in zip(valid_data[:20], id_to_word(valid_data[:20], word_to_id))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert the words in our dataset to vectors of numbers. The traditional approach is to use one-hot encoding method that is usually used for converting categorical values to numerical values. However, one-hot encoded vectors are high-dimensional, sparse and in a big dataset, computationally inefficient. \n",
    "\n",
    "We use [word embeddings](https://en.wikipedia.org/wiki/Word_embedding), which is a way of representing sentence structures or words as n-dimensional vectors (where n is a reasonably high number, such as 200 or 500) of real numbers. Basically, we will assign each word a randomly-initialized vector, and input those into the network to be processed. After a number of iterations, these vectors are expected to assume values that help the network to correctly predict what it needs to, in our case, the probable next word in the sentence. This is shown to be a very effective task in Natural Language Processing, and is a commonplace practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTB_model(object):\n",
    "    def __init__(self):\n",
    "        ######################################\n",
    "        # Setting parameters for ease of use #\n",
    "        ######################################\n",
    "        self.batch_size = 32 # The size for each batch of data\n",
    "        self.num_steps = 20 # The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
    "        self.hidden_size_l1 = 256 # The number of processing units (neurons) in the first hidden layer\n",
    "        self.hidden_size_l2 = 128 # The number of processing units (neurons) in the second hidden layer\n",
    "        self.vocab_size = 10000 # The size of our vocabulary\n",
    "        self.embeding_vector_size = 200 # The size of the embedding vector\n",
    "        self.max_grad_norm = 5 # Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
    "        self._lr = 1.0 # Initial learning rate\n",
    "\n",
    "        #####################################################\n",
    "        # Initializing the model using keras Sequential API #\n",
    "        #####################################################\n",
    "        self._model = Sequential()\n",
    "\n",
    "        ###############\n",
    "        # Input layer #\n",
    "        ###############\n",
    "        self._input_layer = Input(batch_shape=(self.batch_size, self.num_steps)) # Define batch size\n",
    "        self._model.add(self._input_layer)\n",
    "\n",
    "        ####################################################################\n",
    "        # Creating the word embeddings layer and adding it to the sequence #\n",
    "        ####################################################################\n",
    "        self._embedding_layer = layers.Embedding(self.vocab_size, self.embeding_vector_size, trainable=True)\n",
    "        self._model.add(self._embedding_layer)\n",
    "\n",
    "        ##########################################################################\n",
    "        # Creating the LSTM cell structure and connect it with the RNN structure #\n",
    "        ##########################################################################\n",
    "        # This creates only the structure for the LSTM and has to be associated with a RNN unit still.\n",
    "        # The argument  of LSTMCell is size of hidden layer, that is, the number of hidden units of the LSTM (inside A).\n",
    "        # LSTM cell processes one word at a time and computes probabilities of the possible continuations of the sentence.\n",
    "        lstm_cell_l1 = layers.LSTMCell(self.hidden_size_l1)\n",
    "        lstm_cell_l2 = layers.LSTMCell(self.hidden_size_l2)\n",
    "\n",
    "        # By taking in the LSTM cells as parameters, the StackedRNNCells layer junctions the LSTM units to the RNN units.\n",
    "        # RNN cell composed sequentially of stacked simple cells.\n",
    "        stacked_lstm = layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])\n",
    "\n",
    "        ############################################\n",
    "        # Creating the input structure for our RNN #\n",
    "        ############################################\n",
    "        # Input structure is 20x[32x200]\n",
    "        # Considering each word is represended by a 200 dimentional vector, and we have 32-batchs, we create 32 word-vectors of size [32x2000]\n",
    "        # The input structure is fed from the embeddings, which are filled in by the input data\n",
    "        # Feeding a batch of 32 sentences to a RNN:\n",
    "        # - In step 1, first word of each of the 32 sentences (in a batch) is input in parallel.\n",
    "        # - In step 2, second word of each of the 32 sentences is input in parallel.\n",
    "        # The parallelism is only for efficiency.\n",
    "        # Each sentence in a batch is handled in parallel, but the network sees one word of a sentence at a time and does the computations accordingly.\n",
    "        # All the computations involving the words of all sentences in a batch at a given time step are done in parallel.\n",
    "\n",
    "        ########################################################################################################\n",
    "        # Instantiating our RNN model and setting stateful to True to feed forward the state to the next layer #\n",
    "        ########################################################################################################\n",
    "        self._RNNlayer = layers.RNN(stacked_lstm, return_sequences=True, return_state=False, stateful=True, trainable=True)\n",
    "\n",
    "        # Define the initial state, i.e., the model state for the very first data point.\n",
    "        # It initialize the state of the LSTM memory. The memory state of the network is initialized with a vector of zeros and gets updated after reading each word.\n",
    "        self._initial_state = tf.Variable(tf.zeros([self.batch_size, self.embeding_vector_size]), trainable=False)\n",
    "        self._RNNlayer.inital_state = self._initial_state\n",
    "\n",
    "        ############################################\n",
    "        # Adding RNN layer to keras sequential API #\n",
    "        ############################################\n",
    "        self._model.add(self._RNNlayer)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # Instantiating a Dense layer that connects the output to the vocab_size and adding layer to model #\n",
    "        ####################################################################################################\n",
    "        self._dense = layers.Dense(self.vocab_size)\n",
    "        self._model.add(self._dense)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # Adding softmax activation layer and deriving probability to each class and adding layer to model #\n",
    "        ####################################################################################################\n",
    "        self._activation = layers.Activation('softmax')\n",
    "        self._model.add(self._activation)\n",
    "\n",
    "        ##########################################################\n",
    "        # Instantiating the stochastic gradient decent optimizer #\n",
    "        ##########################################################\n",
    "        self._optimizer = optimizers.SGD(learning_rate=self._lr, clipnorm=self.max_grad_norm)\n",
    "\n",
    "        ##############################################################################\n",
    "        # Compiling and summarizing the model stacked using the keras sequential API #\n",
    "        ##############################################################################\n",
    "        self._model.compile(loss=self.crossentropy, optimizer=self._optimizer)\n",
    "        self._model.summary()\n",
    "\n",
    "    def crossentropy(self, y_true, y_pred):\n",
    "        return losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def train_batch(self, _input_data,_targets):\n",
    "        #################################################\n",
    "        # Creating the Training Operation for our Model #\n",
    "        #################################################\n",
    "        # Create a variable for the learning rate\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        # Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
    "        tvars = self._model.trainable_variables\n",
    "\n",
    "        # Define the gradient clipping threshold\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass.\n",
    "            output_words_prob = self._model(_input_data)\n",
    "            # Loss value for this batch.\n",
    "            loss = self.crossentropy(_targets, output_words_prob)\n",
    "            # Average across batch and reduce sum\n",
    "            cost = tf.reduce_sum(loss / self.batch_size)\n",
    "\n",
    "        # Get gradients of loss wrt the trainable variables.\n",
    "        grad_t_list = tape.gradient(cost, tvars)\n",
    "        # Define the gradient clipping threshold\n",
    "        grads, _ = tf.clip_by_global_norm(grad_t_list, self.max_grad_norm)\n",
    "        # Create the training TensorFlow Operation through our optimizer\n",
    "        self._optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def test_batch(self, _input_data, _targets):\n",
    "        ################################################\n",
    "        # Creating the Testing Operation for our Model #\n",
    "        ################################################\n",
    "        output_words_prob = self._model(_input_data)\n",
    "        loss  = self.crossentropy(_targets, output_words_prob)\n",
    "        # Average across batch and reduce sum\n",
    "        cost = tf.reduce_sum(loss / self.batch_size)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    @classmethod\n",
    "    def instance(cls):\n",
    "        return PTB_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741330434.509498  371964 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1430 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">665,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m200\u001b[0m)          │     \u001b[38;5;34m2,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn (\u001b[38;5;33mRNN\u001b[0m)                       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m665,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10000\u001b[0m)        │     \u001b[38;5;34m1,290,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10000\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,955,088</span> (15.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,955,088\u001b[0m (15.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,955,088</span> (15.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,955,088\u001b[0m (15.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiates the PTB_model class\n",
    "model = PTB_model.instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# run_one_epoch takes as parameters the model instance, the data to be fed, training or testing mode and verbose info #\n",
    "#######################################################################################################################\n",
    "def run_one_epoch(model, data, is_training=True, verbose=False):\n",
    "    # Define the epoch size based on the length of the data, batch size and the number of steps\n",
    "    epoch_size = ((len(data) // model.batch_size) - 1) // model.num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.\n",
    "    iters = 0\n",
    "\n",
    "    model._RNNlayer.inital_state = model._initial_state\n",
    "\n",
    "    # For each step and data point\n",
    "    for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.num_steps)):\n",
    "        start_time_step = time.time()\n",
    "\n",
    "        if is_training:\n",
    "            loss = model.train_batch(x, y)\n",
    "        else:\n",
    "            loss = model.test_batch(x, y)\n",
    "\n",
    "        # Add returned cost to costs (which keeps track of the total costs for this epoch)\n",
    "        costs += loss\n",
    "\n",
    "        # Add number of steps to iteration counter\n",
    "        iters += model.num_steps\n",
    "\n",
    "        steps_to_show = [0] + [i for i in range(int(epoch_size/10), epoch_size - int(epoch_size/10), int(epoch_size/10))]\n",
    "\n",
    "        if verbose and step in steps_to_show:\n",
    "            print(f\"\\tStep: {step + 1}/{epoch_size}\")\n",
    "            print(f\"\\t\\telapsed time: {(time.time() - start_time_step):.3f}s - perplexity: {np.exp(costs / iters):.2f} - \\\n",
    "                  speed: {iters * model.batch_size / (time.time() - start_time):.2f} wps\")\n",
    "            print(\"\\n\") if step == steps_to_show[-1] else None\n",
    "    \n",
    "    # Returns the perplexity rating for us to keep track of how the model is evolving\n",
    "    return np.exp(costs / iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "\telapsed time: 282.622s - learning rate: 1.00 - perplexity: 383.32 - val_perplexity: 236.37\n",
      "Epoch 2/5:\n",
      "\telapsed time: 269.311s - learning rate: 1.00 - perplexity: 172.24 - val_perplexity: 170.01\n",
      "Epoch 3/5:\n",
      "\telapsed time: 270.345s - learning rate: 1.00 - perplexity: 129.46 - val_perplexity: 150.01\n",
      "Epoch 4/5:\n",
      "\telapsed time: 274.295s - learning rate: 1.00 - perplexity: 108.60 - val_perplexity: 141.73\n",
      "Epoch 5/5:\n",
      "\telapsed time: 261.806s - learning rate: 1.00 - perplexity: 95.90 - val_perplexity: 138.00\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "decay = 0.5 # The decay for the learning rate\n",
    "max_epoch_decay_lr = 5 # The maximum number of epochs trained with the initial learning rate\n",
    "learning_rate = 1.0 # Initial learning rate\n",
    "train_perplexities = []\n",
    "valid_perplexities = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Define the decay for this epoch\n",
    "    lr_decay = decay ** max((i + 1) - max_epoch_decay_lr, 0.0)\n",
    "    dcr = learning_rate * lr_decay\n",
    "    model._lr = dcr\n",
    "    model._model.optimizer.learning_rate.assign(model._lr)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Epoch {i + 1}/{epochs}:\")\n",
    "    # Run the loop for this epoch in the training mode\n",
    "    train_perplexity = run_one_epoch(model, train_data, is_training=True, verbose=False)\n",
    "    train_perplexities.append(train_perplexity)\n",
    "    # Run the loop for this epoch in the validation mode\n",
    "    valid_perplexity = run_one_epoch(model, valid_data, is_training=False, verbose=False)\n",
    "    valid_perplexities.append(valid_perplexity)\n",
    "\n",
    "    print(f\"\\telapsed time: {(time.time() - start_time):.3f}s - learning rate: {dcr:.2f} - perplexity: {train_perplexity:.2f} - val_perplexity: {valid_perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_perplexities)\n",
    "plt.plot(valid_perplexities)\n",
    "plt.xticks([i for i in range(epochs)], [i + 1 for i in range(epochs)])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set</th>\n",
       "      <th>Validation set</th>\n",
       "      <th>Test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perplexity</th>\n",
       "      <td>95.9</td>\n",
       "      <td>138.0</td>\n",
       "      <td>134.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Training set  Validation set  Test set\n",
       "Perplexity          95.9           138.0    134.36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how effective was our training\n",
    "test_perplexity = run_one_epoch(model, test_data, is_training=False, verbose=False)\n",
    "pd.DataFrame(data={\"Training set\": [train_perplexity], \"Validation set\": [valid_perplexity], \"Test set\": [test_perplexity]}, dtype=float) \\\n",
    ".rename(index={0: 'Perplexity'}).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
